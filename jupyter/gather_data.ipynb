{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078f4807",
   "metadata": {},
   "source": [
    "# Install Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install MetaTrader5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bddbf7",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134ca196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f95e541",
   "metadata": {},
   "source": [
    "# Get all brazilian stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e9dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not mt5.initialize():\n",
    "    print(\"initialize() failed, error code =\", mt5.last_error())\n",
    "    quit()\n",
    "\n",
    "symbols = mt5.symbols_get()\n",
    "symbol_names = [s.name for s in symbols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ee389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_conditions(s):\n",
    "    if 5 <= len(s) <= 6 and not all([i.isdigit() for i in s[-3:]]) and '$' not in s and '@' not in s and any([i.isdigit() for i in s]):\n",
    "        if len(s) == 5 and s[-1] in ['3', '4', '5', '6', '7', '8']:\n",
    "            return True\n",
    "        if len(s) == 6 and s[-2:] == '11':\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17211bfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "symbol_names = [s for s in symbol_names if stock_conditions(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38be6363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a48698e31fe495d8c6c854c305f9cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_symbol_names = []\n",
    "for s in tqdm(symbol_names):\n",
    "    mt5.symbol_select(s)\n",
    "    time.sleep(1)\n",
    "    sc = mt5.symbol_info(s).session_close\n",
    "    sb = mt5.symbol_info(s).bid\n",
    "    sa = mt5.symbol_info(s).ask\n",
    "    sd = mt5.symbol_info(s).session_deals\n",
    "    if sc > 0 and sb > 0 and sa > 0 and sd > 100:\n",
    "        filtered_symbol_names.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b09d7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_names = filtered_symbol_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df8d0ff",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd202c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b69c86a2e6483488d6a059eee038a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/473 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCB41\n",
      "             open   high    low  close  tick_volume  spread  real_volume\n",
      "time                                                                    \n",
      "2018-04-16  13.78  13.79  13.44  13.58         2965       1       410400\n",
      "2018-04-17  13.58  13.78  13.47  13.71         1826       1       297100\n",
      "2018-04-18  13.70  14.08  13.70  14.03         2278       1       362400\n",
      "2018-04-19  14.12  14.12  13.92  14.00         1292       1       188500\n",
      "2018-04-20  14.03  14.06  13.75  13.93         2187       1       312600\n"
     ]
    }
   ],
   "source": [
    "mt5_timeframe = mt5.TIMEFRAME_D1\n",
    "bars_to_download = 2000\n",
    "\n",
    "# download historical data for each symbol\n",
    "dfs = {}\n",
    "for symbol_name in tqdm(symbol_names):\n",
    "    print(symbol_name, end=\"\\r\")\n",
    "    # select symbol\n",
    "    mt5.symbol_select(symbol_name)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # get the earliest date for which data is available\n",
    "    rates = mt5.copy_rates_from(symbol_name, mt5_timeframe, datetime.datetime.now(), bars_to_download)\n",
    "    try:\n",
    "        start_time = rates[-1][0]\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # convert data to a pandas DataFrame\n",
    "    df = pd.DataFrame(rates)\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df.set_index('time', inplace=True)\n",
    "    \n",
    "    # loop over requests to download all available data\n",
    "    while True:\n",
    "        # request historical data\n",
    "        rates = mt5.copy_rates_from(symbol_name, mt5_timeframe, start_time, bars_to_download)\n",
    "        try:\n",
    "            start_time = rates[-1][0]\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "        # convert data to a pandas DataFrame\n",
    "        new_df = pd.DataFrame(rates)\n",
    "        new_df['time'] = pd.to_datetime(new_df['time'], unit='s')\n",
    "        new_df.set_index('time', inplace=True)\n",
    "        \n",
    "        # append new data to the DataFrame\n",
    "        df = pd.concat([new_df, df])\n",
    "    \n",
    "    # add DataFrame to dictionary\n",
    "    dfs[symbol_name] = df\n",
    "\n",
    "# disconnect from MetaTrader5\n",
    "mt5.shutdown()\n",
    "\n",
    "# display the first 5 rows of the first DataFrame\n",
    "print(list(dfs.keys())[0])\n",
    "print(dfs[list(dfs.keys())[0]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7b3d9",
   "metadata": {},
   "source": [
    "# Filtering stocks with 1200 or more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db1bd941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = {}\n",
    "for key in dfs.keys():\n",
    "#     print(dfs[key].dropna().shape[0])\n",
    "    if dfs[key].dropna().shape[0] >= 1200:\n",
    "        final_df[key] = dfs[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a028531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dca06a",
   "metadata": {},
   "source": [
    "# Filter dates that are after 2015-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eb71f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('2015-01-01')\n",
    "end_date = pd.Timestamp.today()\n",
    "calendar_dates = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "# create a new dataframe with the calendar dates\n",
    "calendar_df = pd.DataFrame(index=calendar_dates)\n",
    "\n",
    "# left join all daily dataframes with the calendar dataframe\n",
    "for symbol_name, daily_df in dfs.items():\n",
    "    merged_df = pd.merge(calendar_df, daily_df, how='left', left_index=True, right_index=True)\n",
    "    dfs[symbol_name] = merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb41c62",
   "metadata": {},
   "source": [
    "# Fill missing values and transform to weekly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4db8c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol_name, daily_df in dfs.items():\n",
    "    # fill missing values with average between last and next not-null value\n",
    "    daily_df.interpolate(method='linear', inplace=True, )\n",
    "\n",
    "    # resample to weekly data\n",
    "    weekly_df = daily_df.resample('W', label='right', closed='right').agg({'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last', 'tick_volume': 'sum'})\n",
    "    \n",
    "    # update the DataFrame in the dictionary\n",
    "    dfs[symbol_name] = weekly_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19afaeb",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddaed6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Save the dictionary of dataframes to a file\n",
    "with open('df_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(dfs, f)\n",
    "    \n",
    "with open('df_dict.pickle', 'rb') as f:\n",
    "    loaded_df_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cae1f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = {}\n",
    "for key in loaded_df_dict.keys():\n",
    "    if loaded_df_dict[key].dropna().shape[0] >= 260:\n",
    "        final_df[key] = loaded_df_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "add17133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Save the dictionary of dataframes to a file\n",
    "with open('final_df.pickle', 'wb') as f:\n",
    "    pickle.dump(final_df, f)\n",
    "    \n",
    "with open('final_df.pickle', 'rb') as f:\n",
    "    loaded_df_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52eae053",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = loaded_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b03f7309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = False\n",
    "\n",
    "for key in final_df.keys():\n",
    "    if isinstance(df, bool):\n",
    "        df = final_df[key].rename(columns={\"close\": key})[key]\n",
    "    else:\n",
    "        df = pd.merge(df, final_df[key].rename(columns={\"close\": key})[key], how=\"left\", left_index=True, right_index=True)\n",
    "        \n",
    "df.index.name = 'Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "959111c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.index >= \"2018-05-06\")&(df.index < \"2023-04-16\")].to_excel(\"../data/base_dados2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633c2ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c5284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
